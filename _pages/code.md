---
layout: archive
permalink: /code/
author_profile: true
---

{% include base_path %}

Some of code and model we released for our publications:
* [Code & model](https://github.com/facebookresearch/TimeSformer) for the [Timesformer](https://arxiv.org/abs/2102.05095) paper of ICML 2021.
* <a href="https://github.com/facebookresearch/pytorchvideo"><img width="15%" src="https://raw.githubusercontent.com/hengcv/hengcv.github.io/master/images/pytorchvideo.png"></a>: A deep learning library for video understanding.
* [VMZ](https://github.com/facebookresearch/VMZ): A set of models and code for [R(2+1)D](https://arxiv.org/abs/1711.11248) and [CSN](https://arxiv.org/abs/1904.02811) with [large-scale pre-training](https://arxiv.org/abs/1905.00561).
* The [IDT](http://lear.inrialpes.fr/people/wang/improved_trajectories) feature from our [ICCV 213](https://hal.inria.fr/hal-00873267v2/document) and [IJCV 2016](https://hal.inria.fr/hal-01145834/document) paper.
* The [Dense Trajectories](http://lear.inrialpes.fr/people/wang/dense_trajectories) feature from our [CVPR 2011](https://hal.inria.fr/inria-00583818/document) and [IJCV 2013](https://hal.inria.fr/hal-00725627v2/document) paper. 
